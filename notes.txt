
10-1-15
- Loss on Prediction of first 32 time steps:
  - iteration 16050, loss = 0.07039130, loss/seq_len = 0.00109986, gradnorm = 3.6434e-01
- https://github.com/joanbruna/prediction - data_handling - create_training_timit_cqt

10-7-15
- 1024 timebins for each audio file.
  - 3 seconds / 1024 ~= 3ms per bin
  - 'd' PHN is 70-140Hz ~= 4-8 ms ~= 2-3bins
  - The Phoneme data set does not contain spaces but the text does


10-12-15
- Each cqt vector is 2.048 seconds
- Seems like the middle ~2 seconds are extracted from each file
 -- FCJF0 I did  (2.924812 - 2.048) / 2 = 0.438406

10-13-15
- change N to 32 * (multiple of 32)
- call create_scattfilts
- do invcqt


3-11-16
* https://swarbrickjones.wordpress.com/2015/04/29/convolutional-autoencoders-in-pythontheanolasagne/

3-17-16
* Possible Problems
    * Hasn't completely converged (emm... maybe
210/80000 (epoch 0.525), loss=4.09796, grad norm = 0.901, time/batch = 2.1061s
220/80000 (epoch 0.550), loss=3.63840, grad norm = 0.845, time/batch = 1.9494s
230/80000 (epoch 0.575), loss=3.90146, grad norm = 0.892, time/batch = 1.9440s
240/80000 (epoch 0.600), loss=3.86700, grad norm = 0.881, time/batch = 2.0982s
250/80000 (epoch 0.625), loss=3.61585, grad norm = 0.871, time/batch = 1.9466s
260/80000 (epoch 0.650), loss=3.77548, grad norm = 0.843, time/batch = 1.9483s
270/80000 (epoch 0.675), loss=3.67322, grad norm = 0.864, time/batch = 2.1025s
280/80000 (epoch 0.700), loss=3.77903, grad norm = 0.825, time/batch = 1.9432s
290/80000 (epoch 0.725), loss=3.82479, grad norm = 0.895, time/batch = 1.9500s
300/80000 (epoch 0.750), loss=3.85711, grad norm = 0.839, time/batch = 2.1029s
    * There are some garbage examples (see scattnmf/v4)
        * Perhaps I need to add a buffer to the word extraction script
    * Network needs more capacity
        * Don't want to over fit
    * Use only long words?

    * More data...
        1) Wavelet py code looks unintuitive, no phase information, Will it work with random detail info?
        2) Try STFT with random phase info? (librosa)
        3) Try to get matlab code to work? Reinstall matlab, not guranteed the function would even work...
        4) Manually translate 30 speakers * 500 data points. did 2 * 100 took awhile...


4-20-16
- 1380/40000 (epoch 6.900), train_loss = 7.70260668, grad norm = 4.1305e+00, time/batch = 0.7885s
1/L:0.00066
- 500/40000 (epoch 2.500), train_loss = 9.77965641, grad norm = 3.9056e+00, time/batch = 0.7952s
1/L:0.00086 || 2/(L+m):0.00107 || m:709.709
1/L:0.00083 || 2/(L+m):0.00104 || m:712.737
1/L:0.00083 || 2/(L+m):0.00105 || m:688.755
1/L:0.00076 || 2/(L+m):0.00092 || m:854.978
